import tensorflow as tf
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequenc

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

df = pd.read_csv("your data location")
sentences = []
labels = []
df.shape[0]

for i in range(0,df.shape[0]):
    
    sentences.append(df["text"][i])
    labels.append(df["target"][i])
    
tokens = Tokenizer(oov_token = "<OOV>")
tokens.fit_on_texts(sentences)
word_index = tokens.word_index
sequences = tokens.texts_to_sequences(sentences)
padded = pad_sequences(sequences,padding = "post")
print(padded[0])
print(padded.shape)

model = tf.keras.Sequential([
    tf.keras.layers.Embedding(251229,33),
    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(33)),
    tf.keras.layers.Dense(33, activation = 'relu'),
    tf.keras.layers.Dense(1, activation = 'sigmoid')
 ])
model.compile(loss = 'binary_crossentropy',optimizer = 'adam',metrics = ['accuracy'])


num_epochs = 30
training = model.fit(padded,df["target"],epochs = num_epochs)

sentence_test = []
df_test = pd.read_csv("E:\\Dhruv\\datasets\\test.csv")
for i in range(0,df_test.shape[0]):
    sentence_test.append(df_test["text"][i])
    
sequences_test = tokens.texts_to_sequences(sentence_test)
padded_test = pad_sequences(sequences_test,padding = "post")
targets_test = model.predict(padded_test)
